{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4c7ad528",
   "metadata": {},
   "source": [
    "# 1. Data cleaning "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "709052bf",
   "metadata": {},
   "source": [
    "Purpose: tidy **product_info.csv** into an analysis-ready table.\n",
    "\n",
    "Main steps: drop noisy columns `cols_to_drop`, remove rows missing `rating` or `ingredients`, normalize category hierarchy (fill secondary/tertiary), parse `highlights` and `ingredients` into lists and counts.\n",
    "\n",
    "Outputs: **products_cleaned_base.csv**, **highlight_tag_counts.csv**, **ingredient_token_counts.csv**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6a227a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import ast\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3732c15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved highlight tag counts to: highlight_tag_counts.csv\n",
      "                                  tag  count\n",
      "0                               Vegan   2365\n",
      "1                        Cruelty-Free   1574\n",
      "2                    Clean at Sephora   1438\n",
      "3                    Without Parabens   1282\n",
      "4                   Good for: Dryness   1119\n",
      "5                           Hydrating   1100\n",
      "6   Good for: Dullness/Uneven Texture    856\n",
      "7         Without Sulfates SLS & SLES    727\n",
      "8                        Long-wearing    686\n",
      "9             Clean + Planet Positive    658\n",
      "10                     All Hair Types    632\n",
      "11               Good for: Anti-Aging    585\n",
      "12                    Hyaluronic Acid    560\n",
      "13                 Without Phthalates    479\n",
      "14                     Fragrance Free    477\n",
      "Saved ingredient token counts to: ingredient_token_counts.csv\n",
      "                ingredient_token  count\n",
      "0                       glycerin   4087\n",
      "1                 phenoxyethanol   3802\n",
      "2                caprylyl glycol   2713\n",
      "3                     tocopherol   2660\n",
      "4                       limonene   2464\n",
      "5                    dimethicone   2338\n",
      "6             ethylhexylglycerin   2326\n",
      "7                         silica   2308\n",
      "8                       linalool   2255\n",
      "9                butylene glycol   2211\n",
      "10                   citric acid   2135\n",
      "11                          mica   1959\n",
      "12             potassium sorbate   1779\n",
      "13  caprylic/capric triglyceride   1775\n",
      "14                         water   1768\n",
      "Saved cleaned dataset (with parsed highlights/ingredients) to: products_cleaned_base.csv\n"
     ]
    }
   ],
   "source": [
    "# ----------------------------------------------------\n",
    "# 1. Load data\n",
    "# ----------------------------------------------------\n",
    "# Adjust the path if needed\n",
    "INPUT_PATH = \"data/product_info.csv\"\n",
    "OUTPUT_CLEANED_PATH = \"products_cleaned_base.csv\"\n",
    "OUTPUT_HIGHLIGHT_COUNTS = \"highlight_tag_counts.csv\"\n",
    "OUTPUT_INGREDIENT_COUNTS = \"ingredient_token_counts.csv\"\n",
    "\n",
    "df = pd.read_csv(INPUT_PATH)\n",
    "\n",
    "# ----------------------------------------------------\n",
    "# 2. Drop unwanted columns\n",
    "# ----------------------------------------------------\n",
    "cols_to_drop = [\n",
    "    \"size\",\n",
    "    \"variation_type\",\n",
    "    \"variation_value\",\n",
    "    \"variation_desc\",\n",
    "    \"value_price_usd\",\n",
    "    \"sale_price_usd\",\n",
    "    \"child_max_price\",\n",
    "    \"child_min_price\",\n",
    "]\n",
    "\n",
    "df = df.drop(columns=cols_to_drop, errors=\"ignore\")\n",
    "\n",
    "# ----------------------------------------------------\n",
    "# 3. Drop rows with NaN in rating or ingredients\n",
    "# ----------------------------------------------------\n",
    "df = df[df[\"rating\"].notna()]\n",
    "df = df[df[\"ingredients\"].notna()]\n",
    "\n",
    "# ----------------------------------------------------\n",
    "# 4. Clean category hierarchy: primary / secondary / tertiary\n",
    "# ----------------------------------------------------\n",
    "# Secondary: treat NaNs as \"Primary General\"\n",
    "def fill_secondary(row):\n",
    "    sec = row.get(\"secondary_category\")\n",
    "    if pd.isna(sec):\n",
    "        prim = row.get(\"primary_category\", \"Unknown\")\n",
    "        return f\"{prim} General\"\n",
    "    return sec\n",
    "\n",
    "df[\"secondary_category\"] = df.apply(fill_secondary, axis=1)\n",
    "\n",
    "# Tertiary: treat NaNs as \"General\"\n",
    "if \"tertiary_category\" in df.columns:\n",
    "    df[\"tertiary_category\"] = df[\"tertiary_category\"].fillna(\"General\")\n",
    "\n",
    "# ----------------------------------------------------\n",
    "# 5. Parse 'highlights' column and prepare tag selection\n",
    "# ----------------------------------------------------\n",
    "def parse_list_string(x):\n",
    "    \"\"\"\n",
    "    Safely parse a string that looks like a Python list, e.g.\n",
    "    \"['Vegan', 'Matte Finish']\" -> ['Vegan', 'Matte Finish'].\n",
    "    If NaN or parsing fails, return [].\n",
    "    \"\"\"\n",
    "    if pd.isna(x):\n",
    "        return []\n",
    "    if isinstance(x, list):\n",
    "        return x\n",
    "    try:\n",
    "        parsed = ast.literal_eval(x)\n",
    "        if isinstance(parsed, list):\n",
    "            return parsed\n",
    "        else:\n",
    "            return []\n",
    "    except Exception:\n",
    "        # If it's just a plain string without list syntax, you could decide\n",
    "        # to return [x] or [] – we’ll pick [] to be conservative.\n",
    "        return []\n",
    "\n",
    "# New column with parsed highlights as list\n",
    "if \"highlights\" in df.columns:\n",
    "    df[\"highlights_list\"] = df[\"highlights\"].apply(parse_list_string)\n",
    "else:\n",
    "    df[\"highlights_list\"] = [[] for _ in range(len(df))]\n",
    "\n",
    "# Count all highlight tags (flatten the list of lists)\n",
    "all_highlight_tags = [\n",
    "    tag.strip()\n",
    "    for tags in df[\"highlights_list\"]\n",
    "    for tag in tags\n",
    "    if isinstance(tag, str)\n",
    "]\n",
    "\n",
    "highlight_counter = Counter(all_highlight_tags)\n",
    "\n",
    "# Convert to DataFrame for inspection and manual selection\n",
    "highlight_counts_df = (\n",
    "    pd.DataFrame(\n",
    "        [{\"tag\": tag, \"count\": count} for tag, count in highlight_counter.most_common()]\n",
    "    )\n",
    "    .sort_values(\"count\", ascending=False)\n",
    "    .reset_index(drop=True)\n",
    ")\n",
    "\n",
    "highlight_counts_df.to_csv(OUTPUT_HIGHLIGHT_COUNTS, index=False)\n",
    "print(f\"Saved highlight tag counts to: {OUTPUT_HIGHLIGHT_COUNTS}\")\n",
    "print(highlight_counts_df.head(15))\n",
    "\n",
    "# Optional: simple metric of \"how marketed\" a product is\n",
    "df[\"n_highlights\"] = df[\"highlights_list\"].apply(len)\n",
    "\n",
    "# ----------------------------------------------------\n",
    "# 6. Parse 'ingredients' and data-driven refinement\n",
    "# ----------------------------------------------------\n",
    "# a) Parse ingredients into lists\n",
    "df[\"ingredients_list\"] = df[\"ingredients\"].apply(parse_list_string)\n",
    "\n",
    "# b) Build a cleaned text version: join list and lowercase\n",
    "def ingredients_to_text(ing_list):\n",
    "    if not isinstance(ing_list, list):\n",
    "        return \"\"\n",
    "    # Join with commas to preserve separation\n",
    "    text = \", \".join([str(x) for x in ing_list])\n",
    "    return text.lower()\n",
    "\n",
    "df[\"ingredients_text\"] = df[\"ingredients_list\"].apply(ingredients_to_text)\n",
    "\n",
    "# c) Split by comma into tokens and count frequencies\n",
    "ingredient_tokens = []\n",
    "\n",
    "for text in df[\"ingredients_text\"]:\n",
    "    if not text:\n",
    "        continue\n",
    "    # Split on comma\n",
    "    parts = text.split(\",\")\n",
    "    for p in parts:\n",
    "        token = p.strip()\n",
    "        if token:\n",
    "            ingredient_tokens.append(token)\n",
    "\n",
    "ingredient_counter = Counter(ingredient_tokens)\n",
    "\n",
    "# Choose top N (e.g. 200) most frequent ingredient tokens\n",
    "TOP_N_INGREDIENTS = 200\n",
    "top_ingredients = ingredient_counter.most_common(TOP_N_INGREDIENTS)\n",
    "\n",
    "ingredient_counts_df = pd.DataFrame(\n",
    "    [{\"ingredient_token\": ing, \"count\": cnt} for ing, cnt in top_ingredients]\n",
    ").sort_values(\"count\", ascending=False)\n",
    "\n",
    "ingredient_counts_df.to_csv(OUTPUT_INGREDIENT_COUNTS, index=False)\n",
    "print(f\"Saved ingredient token counts to: {OUTPUT_INGREDIENT_COUNTS}\")\n",
    "print(ingredient_counts_df.head(15))\n",
    "\n",
    "# ----------------------------------------------------\n",
    "# 7. Save base cleaned dataset\n",
    "# ----------------------------------------------------\n",
    "df.to_csv(OUTPUT_CLEANED_PATH, index=False)\n",
    "print(f\"Saved cleaned dataset (with parsed highlights/ingredients) to: {OUTPUT_CLEANED_PATH}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be0ab1c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"products_cleaned_base.csv\")\n",
    "\n",
    "def parse_list_string(x):\n",
    "    if pd.isna(x):\n",
    "        return []\n",
    "    if isinstance(x, list):\n",
    "        return x\n",
    "    try:\n",
    "        parsed = ast.literal_eval(x)\n",
    "        return parsed if isinstance(parsed, list) else []\n",
    "    except Exception:\n",
    "        return []\n",
    "\n",
    "df[\"highlights_list\"] = df[\"highlights\"].apply(parse_list_string)\n",
    "\n",
    "hsel = pd.read_csv(\"highlight_features_selected.csv\")\n",
    "\n",
    "for tag in hsel[\"tag\"]:\n",
    "    col_name = \"tag_\" + tag.lower().replace(\" \", \"_\").replace(\"/\", \"_\").replace(\":\", \"\").replace(\",\", \"\").replace(\"&\", \"and\")\n",
    "    df[col_name] = df[\"highlights_list\"].apply(lambda tags: int(tag in tags))\n",
    "\n",
    "df[\"n_highlights\"] = df[\"highlights_list\"].apply(len)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "40ec548e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"products_cleaned_base.csv\")\n",
    "\n",
    "def parse_list_string(x):\n",
    "    if pd.isna(x):\n",
    "        return []\n",
    "    if isinstance(x, list):\n",
    "        return x\n",
    "    try:\n",
    "        parsed = ast.literal_eval(x)\n",
    "        return parsed if isinstance(parsed, list) else []\n",
    "    except Exception:\n",
    "        return []\n",
    "\n",
    "df[\"ingredients_list\"] = df[\"ingredients\"].apply(parse_list_string)\n",
    "\n",
    "def ingredients_to_text(ing_list):\n",
    "    if not isinstance(ing_list, list):\n",
    "        return \"\"\n",
    "    return \", \".join([str(x) for x in ing_list]).lower()\n",
    "\n",
    "df[\"ingredients_text\"] = df[\"ingredients_list\"].apply(ingredients_to_text)\n",
    "\n",
    "isel = pd.read_csv(\"ingredient_features_selected.csv\", sep=\";\")\n",
    "\n",
    "group_to_tokens = {}\n",
    "for _, row in isel.iterrows():\n",
    "    group = row[\"group_name\"]\n",
    "    token = str(row[\"token\"]).lower()\n",
    "    group_to_tokens.setdefault(group, []).append(token)\n",
    "\n",
    "for group_name, tokens in group_to_tokens.items():\n",
    "    df[group_name] = df[\"ingredients_text\"].apply(\n",
    "        lambda txt: int(any(tok in txt for tok in tokens))\n",
    "    )\n",
    "\n",
    "df[\"n_ingredients\"] = df[\"ingredients_text\"].apply(\n",
    "    lambda txt: len([p for p in txt.split(\",\") if p.strip()])\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e1956695",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 7322 entries, 0 to 7321\n",
      "Data columns (total 42 columns):\n",
      " #   Column                        Non-Null Count  Dtype  \n",
      "---  ------                        --------------  -----  \n",
      " 0   product_id                    7322 non-null   object \n",
      " 1   product_name                  7322 non-null   object \n",
      " 2   brand_id                      7322 non-null   int64  \n",
      " 3   brand_name                    7322 non-null   object \n",
      " 4   loves_count                   7322 non-null   int64  \n",
      " 5   rating                        7322 non-null   float64\n",
      " 6   reviews                       7322 non-null   float64\n",
      " 7   ingredients                   7322 non-null   object \n",
      " 8   price_usd                     7322 non-null   float64\n",
      " 9   limited_edition               7322 non-null   int64  \n",
      " 10  new                           7322 non-null   int64  \n",
      " 11  online_only                   7322 non-null   int64  \n",
      " 12  out_of_stock                  7322 non-null   int64  \n",
      " 13  sephora_exclusive             7322 non-null   int64  \n",
      " 14  highlights                    5621 non-null   object \n",
      " 15  primary_category              7322 non-null   object \n",
      " 16  secondary_category            7322 non-null   object \n",
      " 17  tertiary_category             7322 non-null   object \n",
      " 18  child_count                   7322 non-null   int64  \n",
      " 19  highlights_list               7322 non-null   object \n",
      " 20  n_highlights                  7322 non-null   int64  \n",
      " 21  ingredients_list              7322 non-null   object \n",
      " 22  ingredients_text              7322 non-null   object \n",
      " 23  has_fragrance                 7322 non-null   int64  \n",
      " 24  has_fragrance_allergens       7322 non-null   int64  \n",
      " 25  has_drying_alcohols           7322 non-null   int64  \n",
      " 26  has_silicones                 7322 non-null   int64  \n",
      " 27  has_humectants                7322 non-null   int64  \n",
      " 28  has_emollient_oils            7322 non-null   int64  \n",
      " 29  has_fatty_alcohols            7322 non-null   int64  \n",
      " 30  has_exfol_acids_aha           7322 non-null   int64  \n",
      " 31  has_exfol_acids_bha           7322 non-null   int64  \n",
      " 32  has_antioxidant_vitamins      7322 non-null   int64  \n",
      " 33  has_niacinamide               7322 non-null   int64  \n",
      " 34  has_caffeine                  7322 non-null   int64  \n",
      " 35  has_adenosine                 7322 non-null   int64  \n",
      " 36  has_barrier_soothing          7322 non-null   int64  \n",
      " 37  has_chemical_sunscreen        7322 non-null   int64  \n",
      " 38  has_mineral_sunscreen         7322 non-null   int64  \n",
      " 39  has_common_preservatives      7322 non-null   int64  \n",
      " 40  has_hair_conditioning_agents  7322 non-null   int64  \n",
      " 41  n_ingredients                 7322 non-null   int64  \n",
      "dtypes: float64(3), int64(28), object(11)\n",
      "memory usage: 2.3+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "streamlit_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
